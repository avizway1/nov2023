_________________________________________________________________________________

S3 : Simple Storage Service :
-
Object based storage :  We cannot install/run any applications/os. : Dropbox / GDrive 
--> Designed to flat files.

Block based storage : Designed to run OS, We can install/run applications.. : EBS, Instance store volumes. : EC2 
Storage over the network : Storage runs over the network and it can be mounted to multiple devices. : EFS, FSx : EC2

--> Designed to store objects. We can store any flat files.
--> We store data in BUCKETS.
--> Bucket names should be unique across the globe.
--> Defualtly, we can create 100 buckets, This is a soft limit.
--> We can store unlimited data in a bucket.
--> No Pre-provisioning required.
--> Bucket naming limitations.
	--> Min char 3, Max 63 char length
	--> Bucket name should be in small , and numeric
	--> Bucket name should not start with .
	--> Should not end with . , No adjesent ..
	--> Bucket name should not resemble IP address format. (192.168.100.1)

--> We can upload objects to this buckets.
--> Min obj size : 0 bytes.. Max Obj size: 5 TB
--> S3 is a global service. Doesn't required region selection, when nyou are using s3 service.
--> While creating bucket, we need to choose the region. Data physically resides at this regions AZs. 

https://s3.ap-south-1.amazonaws.com/bucketname/objectname (standard URL)
https://bucketname.s3.ap-south-1.amazonaws.com/objectname (virtual path)
https://bucketname.s3.amazonaws.com/objectname (virtual path)

Virtual paths won't work if we have . in bucket names.

To make an object public : 

1. Block Public Access settings for this account : Account Level Blocking
2. Block public access (bucket settings) : Bucket level Blocking
--> We should make an object public, then only Object URLs works.
** Object Ownership : ACLs enabled
3. Make object public. (Select object --> actions --> last option --> make public using acl)

S3 Free Tier ELigibility : 
5 GB Standard Storage
--> 2000 PUT (Upload) / 20,000 GET (Download)
_______________________________________________________________________________

GDrive : 100 gb plan						S3	: no pre provisioning req

20 gb Daily									S3-Standard
20 gb Infreq 								Standard-IA / OneZOne-IA
10 gb don't know when to access				Intelligent Tier
10 gb archive								Glacier / Glacier-DA

30gb

99.99% Ava
99.999999999 % Durability


S3 Storage Classes : 

--> S3 Standard : Defualt storage class for all the data we upload to s3. Data will be available immedeatly.
Designed to store : Frequently accessed data. 
Availability : 99.99%,  Durability: 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> Standard-IA : Data will be available immedeatly. Designed to store : infrequently accessed data
Avai : 99.9%, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> One Zone-IA : Data will be available immedeatly. Designed to store : infrequently accessed data. Store only non-critical data
Avai : 99.5 %, Durability : 99.999999999 (11 9's) 
Data replicates across : 1 AZs

--> Glacier Flexible Retrieval (Formerly Glacier) : Long-term data archiving with retrieval times ranging from minutes to hours. Data won't be available immedeatly. We need to initiate a data restration to view the data. Restoration takes (1 min - 5 Hrs)
Avai : 99.99 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

--> Glacier Instant Retrieval : Long-lived archive data accessed once a quarter with instant retrieval in milliseconds. 

--> Glacier Deep Archieve : Long-term data archiving with retrieval times ranging from 12 hrs. Data won't be available immedeatly. We need to initiate a data restration to view the data. Restoration takes (5 - 12 Hrs)
Avai : 99.99 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs
..

S3 Intelligent Tier : If we have unknown access pattern, we can choose. 
Avai : 99.9 %, Durability : 99.999999999 (11 9's) 
Data replicates across : >= 3 AZs

RRS : Redused Redundancy Storage : Not Recommanded : Less durability.. 
Durability : 99.99%, As we have less durability we have high chances to loss the data when compared to another storage classes.


S3 Pricing : 
--> How much data we are storing.
--> How many GET/PUT operations (uploads/downloaded object count)
--> Data retrivals

Glacier data retrival : 
Bulk retrieval : Typically within 5-12 hours.
Standard retrieval : Typically within 3-5 hours.
Expedited retrieval : Typically within 1-5 minutes when retrieving less than 250 MB.

** Only S3 standard comes under free tier eligibility.

______________________________________________________________________________________

Task :  In Your Personal Accounts:
--> Enable "Free tier alerts". Login using root user/iam user with admin permissions..
Preferences --> Billing preferences --> Receive Free Tier Usage Alerts --> Enable and enter valid email address.

Task 2 : Create an s3 bucket, Upload an object, Make object public accesable.


==============================================================================================

D: 27/12/2023

If you are typing "Delete" ==> you'll get delete Marker. 
If you are typing "perm Delete" ==> You wont get Delete marker.

Delete the "Delete Marker" to get your object back.
_________

Version : AWS maintains multiple copies in s3 bucket. 
--> Defaultly versioning will be in Suspended state.

--> When versioning is enabled on bucket, If we delete an object

Versioning : HIDE
--> S3 will show most recent uploaded object only / Current version objects.
--> We will get a Delete Marker. 
--> TO get object back / undo delete, Set Version to SHOW, Delete the delete marker.

Versioning : SHOW
--> If we delete an object, it deletes permanently.
_____________________________________________________________________________________

Life Cycle Management Rule : 
--> We can apply Rule to entire bucket
--> We can limit rule to a prefix (Folder)
--> We can limit rule to objects by specifing a "Tag"


S3 Standard --> StandardIA/IT --> Glacier --> Delete
S3 Standard --> Glacier --> Delete
S3 Standard --> Delete

____________________

CRR / SRR : 
--> Source bucket and destination bucket must be enabled with versioning. 
--> Existing objects will not replicate to the destination bucket.
--> All future / subsequent uploads will replicate to destination bucket. 

RTC : Replication time control : Data replicates to destination bucket with in 15 Min. (99.99% of the data) : COST US

___

Data transfer from One region to another region "cost us".
Data transfer within a region won't cost us anything.
_______________________

aws s3 sync s3://sourcebucket s3://Targetpath		==> 12:00AM   (task scheduler / cron job)

aws s3 sync localfolder s3://s3backupbucket

_______________________

Task 1 : Create a bucket in N Virginia, Configure Versioning and test it. 

Task 2 :  Create another bucker in N Virginia region only.. configure same region replication between these buckets.

Task 3 : Create a Life CYcle management rule to transit current version objects from s3 standard to Delete after 1 Day.
Transit previous version objects to Delete after 1 Day.

===============================================================================

D: 28/12/2023

--> In-Transit Encryption : 
	SSL (Secure socket layer) / TLS (Transport layer secure)

--> SSE (Server Side Encryption) / At-rest : 

SSE-S3 : S3 platform generates and manages the key material. whoever have valid access on S3 platform can decrypt/view the data. (An encryption key that Amazon S3 creates, manages, and uses for you). AES-256
--> We need to use this to make any data public.

SSE-KMS : Key Management Service : 
	KMS (AWS managed keys) (aws/s3) DMK (Default Master Key) : KMS Service generates and manages the key material. whoever have valid access on S3 platform can decrypt/view the data. We cannot delete these keys. 
--> We cannot make data public using this keys.

	 CMK (Customer managed keys) : KMS Service generates and manages the keymaterial.
Along with S3 platform, the IAM user need to have valid permissions on ENCRYPTION KEY also. 
NO FREE TIER ELIGIBILITY.

	SSE-C (Customer Provided Key): Customer generates and upload the key material to KMS and KMS uses this key material to encrypt/decrypt the data. Customer can change the key material at any time. 
NO FREE TIER ELIGIBILITY.

--> CSE (Client Side Encryption) : 
Before uploading data to s3 platform, we can use our own software/applications to encrypt the data. That encryptrd data we can send to s3. AWS is not completely responsible for this mechanism.

Encryption key generation : 
--> Choose key type : Symmetric /Asymetric : Symetric as s3 supports
--> Choose key Administrator
--> Choose Key Users
--> Review and create


SSE-S3 : S3 created key and key material, No Addl Permisisons on Encry key, Only S3 access is fine.
SSE-KMS DMK : KMS created key and key material, No Addl Permisisons on Encry key, Only S3 access is fine.
SSE-KMS CMK : Customer Creates key and KMS manages key material, Along with S3 access, User/role should have "Key Usage" permissions.
SSE-KMS Customer provided : Customer Create key and Customer provide key material, Along with S3 access, User/role should have "Key Usage" permissions.

---------------------------------------------

What is Presign URL :  Short lived urls. 
--> Without making bucket/object public, we can share an s3 object with presign url, this URL works only for sometime.

---

How can we manage s3 platform with 3rd party applications.!!

--> S3 browser, Cloudberry Explorer, CyberDuck and WinSCP.

---

Task : Try to access s3 using 3rd party applications. (S3 browser, Cyberduck, Cloudberry explorer, winscp)
Steps : Create an IAM user provide s3 readonly/fullaccess, generate Accesskey and SecretKey. Use this with 3rd party tool.

Task 2 : What is presigned URL. Configure an object to generate a presign url to expire after 60 sec.

Task 3 : Enable Encryption on s3 bucket and test it. (SSE-S3/AWS Managed key KMS-DMK)
*** practice in Sandbox if you want to test CMK (it will cost us) **

===========================================================================================================

**Personal Account**
Task 4 : Create a policy to allow everything in an AWS account S3 platform, But user should be able to create a bucket in "ap-south-1" region only.
--> Create a bucket in "mumbai", it should work... But if he try to create bucket in any other region it should fail.

1. Create a policy allow anything but only on mumbai region. (copy policy from S3FullAccess)
2. Create an IAM user and allocate Newly created policy
3. Login as IAM user, Navigate to S3, Try to create a bucket in mumbai, should allow.. SHould deny if you choose any other region.

Task 5 : Configure Replication Rule to replicate data from Account-1 s3 bucket to account-2 s3 bucket.

====================================================================================================

In-Transit : When data is in transit state, it will be encrypted with SSL/TLS certificate. AWS is responsible for S3/other services. If it is our own website, we need to genrate and apply ssl/tls certificate.

Client Side encryption : CSE : Sender/customer is sole responsbile. before sending data, we are applying encryption methods. AWS is not responsible for this.


SSE / Server Side Encryption / At-Rest Encry : 


SSE-S3 : THis is default encryption for our s3 buckets. S3 platform generates and manages the key material.
Whoever has access to s3 platform, they can decrypt the data.


SSE-DMK Default Master key : KMS platform generates and manages the key material.
Whoever has access to s3 platform, they can decrypt the data.
AWS KMS generates these keys based on our services usage on AWS. We cannot delete these. 


SSE-CMK Customer Managed Keys : Customer creates the key, KMS platform manages the key material.
Along with access to s3 platform, user should have "Key Usage" permissions to decrypt the data.
==> COST US .. You can try in sandbox.
==> AWS generate the key material every year.
==> We cannot make data public if our s3 bucket is encrypted using this keys.


SSE-C (Customer Provided) : Customer creates the key, Customer manages the key material.
Along with access to s3 platform, user should have "Key Usage" permissions to decrypt the data.
==> COST US .. You can try in sandbox.
==> We cannot make data public if our s3 bucket is encrypted using this keys.

https://www.youtube.com/watch?v=r17Z75TqjU0


==============================================================================================

D: 29/12/2023

S3 Static Website Hostic : 

--> We need to make data public read, then only our website will deliver. 
--> Purchased Domain name should be same as Bucket name. 
http://learnaws.co.in.s3-website.ap-south-1.amazonaws.com  ==> learnaws.co.in

http status codes :
2XX : OK/Success
3XX : Redirection
4XX : Client sider error
5XX : Server sider error

Task : Download a template from Internet. Deliver the webiste using s3 - static webiste feature.


https://www.free-css.com/free-css-templates

------------

Event notifications : 

--> SNS : Simple Notification Service : 1000 EMAILs Free Tier eligibility
--> SQS : Simple Queue Service
--> Lambda 

--> Make sure you edit the SNS topic's "Access Policy to everyone".


------------

Object Lock : 

--> Versioning must be enabled.

Permanently allows objects in this bucket to be locked. Additional Object Lock configuration is required in bucket details after bucket creation to protect objects in this bucket from being deleted or overwritten.

Governance : Users with specific IAM permissions can overwrite or delete protected object versions during the retention period.

Compliance : No users can overwrite or delete protected object versions during the retention period.

_____

Performance : 
3500 PUT Object per second per prefix
5500 GET Object per second per prefix

--> maintain/Increase the uniqueness for the object names.
--> Use more prefixes (folders)


My Req : i want 10,000 Uploads / Sec.. 

Bucket : 5500 uploads/sec.. 
--> folder1 --> 5500
--> folder2 --> 5500
--> folder3 --> 5500

-----

Monitoring S3 Bucket : 

Free Metrics:
Total number of objects
Total bucket size

We do have an option to enable paid metrics.

-----


Storage Class Analysis : Analyze storage access patterns to help you decide when to transition objects to the appropriate storage class.

_______

Transfer acceleration : Uses Edge locations for data transfer. (COST US)
S3 Transfer Acceleration is not supported for buckets with periods (.) in their names

https://s3-accelerate-speedtest.s3-accelerate.amazonaws.com/en/accelerate-speed-comparsion.html?region=ap-south-1&origBucketName=2505-avinash





storage classes
Versioning
life cycle management rule
replication rules
encryption
bucket policy

events














